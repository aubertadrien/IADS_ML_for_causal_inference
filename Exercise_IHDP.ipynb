{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise IHDP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubertadrien/IADS_ML_for_causal_inference/blob/main/Exercise_IHDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBoPcfD9l9V8"
      },
      "source": [
        "# Causal Inference - Exercise (IHDP)\n",
        "\n",
        "This is an opportunity for everyone to put into practice everything we have learnt so far. The data for this exercise comes from Infant Health Development Program study and was modified specifically for causal inference estimation purposes. More precisely, this dataset was formally introduced by [Hill (2011)](https://doi.org/10.1198/jcgs.2010.08162). It is a commonly used semi-simulated dataset in the CI community that combines pre-treatment covariates (X) and treatment assignments (T) from a real study, and simulated outcomes (Y). Because all outcomes are generated (both $y_1$ and $y_0$), we can measure individual as well as average treatment effect errors. For training purposes, only one of the outcomes is available to the estimator. The other is hidden and used only for evaluation purposes.\n",
        "\n",
        "The experiment where the covariates come from measured various aspects of premature infants and their mothers, and how receiving specialised childcare affected the cognitive test score of the infants later on. The treatment groups are made imbalanced by removing a subset of the treated individuals. The variables are a mixture of contonuous and binary features. Treatment is binary. The outcome Y is continuous. Overall, we have 25 background features X. The data consists of 747 samples (139 treated, 608 control)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcflqEHyquI_"
      },
      "source": [
        "In terms of evaluation metrics, we are interested in predicting both individual and average treatment effects for this task. As the outcomes are simulated, we have access to both true outcomes $\\mathcal{Y}_1$ and $\\mathcal{Y}_0$ for each individual (i). As a result, we have access to true ITEs and true ATE:\n",
        "\n",
        "$$ITE^{(i)} = \\mathcal{Y}_1^{(i)} - \\mathcal{Y}_0^{(i)}$$\n",
        "\n",
        "$$ATE = \\mathbb{E}[ITE]$$\n",
        "\n",
        "We can define our predictions as:\n",
        "\n",
        "$$\\widehat{ITE}^{(i)} = \\hat{y}_1^{(i)} - \\hat{y}_0^{(i)}$$\n",
        "\n",
        "$$\\widehat{ATE} = \\frac{1}{n}\\sum \\limits_{i=1}^{n}\\widehat{ITE}^{(i)}$$\n",
        "\n",
        "This allows us to define measurement errors with respect to each as:\n",
        "\n",
        "$$\\epsilon_{PEHE} = \\sqrt{\\frac{1}{n}\\sum \\limits_{i=1}^{n}(\\widehat{ITE}^{(i)} - ITE^{(i)})^2}$$\n",
        "\n",
        "$$\\epsilon_{ATE} = \\left| \\widehat{ATE} - ATE \\right|$$\n",
        "\n",
        "Where PEHE stands for Precision in Estimation of Heterogeneous Effect, and which essentially is a Root Mean Squared Error (RMSE) between predicted and true ITEs. Implementations of both metrics are provided below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao4shEd7IRNb"
      },
      "source": [
        "def rmse(a, b):\n",
        "    return np.sqrt(((a - b)**2).mean())\n",
        "\n",
        "def ate_error(pred_te, true_te):\n",
        "  return np.abs(np.mean(pred_te) - np.mean(true_te))\n",
        "\n",
        "def pehe_error(pred_te, true_te):\n",
        "  return rmse(true_te, pred_te)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-3Z9QlR1tdA"
      },
      "source": [
        "We suggest the following steps:\n",
        "1. Import packages.\n",
        "    1. Remember to install EconML if you want to use it.\n",
        "2. Data.\n",
        "    1. Can be accessed at the following URLs:\n",
        "        1. Training: https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_train.npz\n",
        "        2. Testing: https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_test.npz\n",
        "    2. Use 'wget' command to download them into the notebook (or upload manually).\n",
        "    3. Explore the data (print a few samples, plot distributions - see plot_dist function below).\n",
        "3. Data pre-processing.\n",
        "    1. No data splitting required (train and test already provided).\n",
        "    2. Scaling.\n",
        "4. Train estimators of your choice (re-use already presented ones or explore different methods.\n",
        "  1. EconML - [CATE estimators](https://econml.azurewebsites.net/reference.html#cate-estimators).\n",
        "  2. scikit-learn - [supervised methods](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning).\n",
        "5. Make predictions.\n",
        "6. Evaluate your models.\n",
        "    1. Measure ATE and PEHE errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcy1W32ix3o8"
      },
      "source": [
        "def _trim_axs(axs, N):\n",
        "    axs = axs.flat\n",
        "    for ax in axs[N:]:\n",
        "        ax.remove()\n",
        "    return axs[:N]\n",
        "\n",
        "def plot_dist(data, bins=10):\n",
        "    \"\"\"\n",
        "    data: 2-dimensional numpy array\n",
        "    bins: number of bins in the histograms\n",
        "    \"\"\"\n",
        "    if data.shape[1] > 1:\n",
        "        sq = math.sqrt(data.shape[1])\n",
        "        d_ceil = math.ceil(sq)\n",
        "        d_floor = math.floor(sq)\n",
        "\n",
        "        if (d_ceil * d_floor) >= data.shape[1]:\n",
        "            n_rows = d_floor\n",
        "            n_cols = d_ceil\n",
        "        else:\n",
        "            n_rows = n_cols = d_ceil\n",
        "\n",
        "        _, axs = plt.subplots(n_rows, n_cols)\n",
        "        axs = _trim_axs(axs, data.shape[1])\n",
        "\n",
        "        for i, ax in enumerate(axs):\n",
        "            ax.hist(data[:, i], bins=bins)\n",
        "    else:\n",
        "        plt.hist(data, bins=bins)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start of the exercise:\n",
        "1. Import packages."
      ],
      "metadata": {
        "id": "O7EGUQX9A4LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install econml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmWktr4sA3QE",
        "outputId": "4b1e12ac-b9e2-4d93-a9c9-bce567ee27bc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: econml in /usr/local/lib/python3.7/dist-packages (0.13.1)\n",
            "Requirement already satisfied: shap<0.41.0,>=0.38.1 in /usr/local/lib/python3.7/dist-packages (from econml) (0.40.0)\n",
            "Requirement already satisfied: sparse in /usr/local/lib/python3.7/dist-packages (from econml) (0.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from econml) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn<1.2,>0.22.0 in /usr/local/lib/python3.7/dist-packages (from econml) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from econml) (1.3.5)\n",
            "Requirement already satisfied: dowhy<0.8 in /usr/local/lib/python3.7/dist-packages (from econml) (0.7.1)\n",
            "Requirement already satisfied: statsmodels>=0.10 in /usr/local/lib/python3.7/dist-packages (from econml) (0.10.2)\n",
            "Requirement already satisfied: scipy>1.4.0 in /usr/local/lib/python3.7/dist-packages (from econml) (1.7.3)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from econml) (2.2.3)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from econml) (1.1.0)\n",
            "Requirement already satisfied: sympy>=1.4 in /usr/local/lib/python3.7/dist-packages (from dowhy<0.8->econml) (1.7.1)\n",
            "Requirement already satisfied: pydot>=1.4 in /usr/local/lib/python3.7/dist-packages (from dowhy<0.8->econml) (1.4.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from dowhy<0.8->econml) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->econml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->econml) (2022.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot>=1.4->dowhy<0.8->econml) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->econml) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.2,>0.22.0->econml) (3.1.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap<0.41.0,>=0.38.1->econml) (0.0.7)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap<0.41.0,>=0.38.1->econml) (21.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap<0.41.0,>=0.38.1->econml) (0.51.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap<0.41.0,>=0.38.1->econml) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap<0.41.0,>=0.38.1->econml) (4.64.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.10->econml) (0.5.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.4->dowhy<0.8->econml) (1.2.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap<0.41.0,>=0.38.1->econml) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap<0.41.0,>=0.38.1->econml) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from econml.metalearners import XLearner\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nEpe2kqeBoDk"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data."
      ],
      "metadata": {
        "id": "i5snWR5tBcuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training data:\n",
        "!wget https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_train.npz\n",
        "data_train = np.load('ihdp_train.npz')\n",
        "\n",
        "#Testing data:\n",
        "!wget https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_test.npz\n",
        "data_test = np.load('ihdp_test.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFrcxITkBfRt",
        "outputId": "f0cca801-7e51-4044-c2c7-4654ab9e9a64"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-28 15:22:32--  https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_train.npz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dmachlanski/iads-summer-school-causality-2022/main/labs/data/ihdp_train.npz [following]\n",
            "--2022-07-28 15:22:32--  https://raw.githubusercontent.com/dmachlanski/iads-summer-school-causality-2022/main/labs/data/ihdp_train.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 151488 (148K) [application/octet-stream]\n",
            "Saving to: ‘ihdp_train.npz’\n",
            "\n",
            "\rihdp_train.npz        0%[                    ]       0  --.-KB/s               \rihdp_train.npz      100%[===================>] 147.94K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-07-28 15:22:32 (53.3 MB/s) - ‘ihdp_train.npz’ saved [151488/151488]\n",
            "\n",
            "--2022-07-28 15:22:32--  https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_test.npz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dmachlanski/iads-summer-school-causality-2022/main/labs/data/ihdp_test.npz [following]\n",
            "--2022-07-28 15:22:32--  https://raw.githubusercontent.com/dmachlanski/iads-summer-school-causality-2022/main/labs/data/ihdp_test.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17760 (17K) [application/octet-stream]\n",
            "Saving to: ‘ihdp_test.npz’\n",
            "\n",
            "ihdp_test.npz       100%[===================>]  17.34K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 15:22:32 (74.6 MB/s) - ‘ihdp_test.npz’ saved [17760/17760]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('ihdp_train.npz')\n",
        "data = np.load('ihdp_test.npz')"
      ],
      "metadata": {
        "id": "NYuNWuspgppM"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the data:\n",
        "print(data_train.files)\n",
        "print(data_test.files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIC-5SaYCo1l",
        "outputId": "cb256dec-26ca-46a1-a0ca-9b873f8f59ff"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['x', 't', 'y', 'te']\n",
            "['x', 't', 'y', 'te']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(data_train.head()) --> not attribute head so impossible to see them in a table?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "tS3EGNPIDjnE",
        "outputId": "88a111e5-453d-4387-fff8-012bea22e015"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-05a5eccbea1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NpzFile' object has no attribute 'head'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for f in data_train.files:\n",
        "  print(f'{f}: {data_train[f].shape}')\n",
        "\n",
        "for f in data_test.files:\n",
        "  print(f'{f}: {data_test[f].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVHrvL0SC9JU",
        "outputId": "6ba2ff91-9e6d-48d7-bd31-b39c0bad8345"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: (672, 25)\n",
            "t: (672, 1)\n",
            "y: (672, 1)\n",
            "te: (672, 1)\n",
            "x: (75, 25)\n",
            "t: (75, 1)\n",
            "y: (75, 1)\n",
            "te: (75, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape the variables (for the train dataset only):\n",
        "x_train = data_train['x']#.reshape(-1, 1) --> not single dimension so should not be reshaped\n",
        "t_train = data_train['t'].reshape(-1, 1)\n",
        "y_train = data_train['y']#.reshape(-1, 1)\n",
        "te_train = data_train['te']#.reshape(-1, 1)\n",
        "\n",
        "x_test = data_test['x']#.reshape(-1, 1)\n",
        "t_test = data_test['t'].reshape(-1, 1)\n",
        "y_test = data_test['y']#.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "i8Vav7VzQUis"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the distributions:\n",
        "bins=20\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "axs[0].hist(t_train, bins=bins) #pre-treatment covariates\n",
        "axs[1].hist(te_train, bins=bins) #treatment\n",
        "axs[2].hist(y_train, bins=bins) #outcome\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "PmbZXMMsQBP-",
        "outputId": "d30dc750-8a97-4a3c-8fa5-4d023960328a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Data pre-processing.\n",
        "\n",
        "    No data splitting required (train and test already provided).\n",
        "    \n",
        "    Scaling. => idem not necessary "
      ],
      "metadata": {
        "id": "Uxb9qOezVOqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scaler_x = StandardScaler() #standardised the age to 0 (some models are sensitive to unstandardised variables)\n",
        "#x_train = scaler_x.fit_transform(X)\n",
        "#x_train = X"
      ],
      "metadata": {
        "id": "8snSYmyIWTtm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_train.files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO8lOL_7Wkpl",
        "outputId": "3b896aa1-c8c8-4ac8-f3fe-37c908045ae8"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['x', 't', 'y', 'te']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga9ahl_pYnPf",
        "outputId": "09ad10f1-6c94-4562-fd13-7b173cdd4238"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Train estimators of your choice (re-use already presented ones or explore different methods).\n",
        "\n",
        "    EconML - CATE estimators.\n",
        "\n",
        "    scikit-learn - supervised methods."
      ],
      "metadata": {
        "id": "TyJTyNNeTwLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest:"
      ],
      "metadata": {
        "id": "a5LGCwzZaShN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "#OU AVEC LassoLarsCV et lr.fit ???? et dr.fit (doubly robust learner)???\n",
        "\n",
        "# Train on the training data.\n",
        "# In the supervised setting, our usual X here consists of X and T.\n",
        "# The target is Y - the outcome.\n",
        "# Input: [X, T], output: Y.\n",
        "rf.fit(np.concatenate([x_train, t_train], axis=1), y_train.flatten())\n",
        "\n",
        "# Predictions\n",
        "# Note we set T to a specific value for ALL individuals.\n",
        "# These are interventional distributions - P(Y|X, do(T=t)).\n",
        "\n",
        "# Training predictions: (NB: not necessary to do it on the training part but good to compare both samples)\n",
        "# Predict Y_0 given [X, 0]\n",
        "rf_y0_in = rf.predict(np.concatenate([x_train, np.zeros_like(t_train)], axis=1))\n",
        "# Predict Y_1 given [X, 1]\n",
        "rf_y1_in = rf.predict(np.concatenate([x_train, np.ones_like(t_train)], axis=1))\n",
        "\n",
        "# Test predictions (model's generalisation to unseen examples):\n",
        "# Predict Y_0 given [X, 0]\n",
        "rf_y0_out = rf.predict(np.concatenate([x_train, np.zeros_like(t_train)], axis=1))\n",
        "# Predict Y_1 given [X, 1]\n",
        "rf_y1_out = rf.predict(np.concatenate([x_train, np.ones_like(t_train)], axis=1))\n",
        "\n",
        "# Compute ITEs (training and test)\n",
        "# ITE = Y_1 - Y_0\n",
        "rf_te_in = rf_y1_in - rf_y0_in\n",
        "rf_te_out = rf_y1_out - rf_y0_out"
      ],
      "metadata": {
        "id": "oPWWvD8ST6z3"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest with IPW:"
      ],
      "metadata": {
        "id": "4FpXXdYfaXql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Necessary to compute the sample weights with the following function:\n",
        "def get_ps_weights(clf, x, t):\n",
        "  ti = np.squeeze(t)\n",
        "  clf.fit(x, ti)\n",
        "  ptx = clf.predict_proba(x).T[1].T + 0.0001 #predict_proba because we want to predict the probability for class 0 and class 1 (here 1 only); '0.0001' added to not divided it by '0'\n",
        "  return ti / ptx + ((1.0 - ti) / (1.0 - ptx))"
      ],
      "metadata": {
        "id": "vQ_T_12HaKji"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the sample weights\n",
        "prop_clf = RandomForestClassifier()\n",
        "weights = get_ps_weights(prop_clf, x_train, t_train)\n",
        "\n",
        "# Train the regressor\n",
        "rf_ipsw = RandomForestRegressor()\n",
        "rf_ipsw.fit(np.concatenate([x_train, t_train], axis=1), y_train.flatten(), sample_weight=weights) #'sample_weight=weights' added at the end compare to the 1st model w/o weights\n",
        "\n",
        "# Make predictions\n",
        "rf_ipsw_y0_in = rf_ipsw.predict(np.concatenate([x_train, np.zeros_like(t_train)], axis=1))\n",
        "rf_ipsw_y1_in = rf_ipsw.predict(np.concatenate([x_train, np.ones_like(t_train)], axis=1))\n",
        "\n",
        "rf_ipsw_y0_out = rf_ipsw.predict(np.concatenate([x_test, np.zeros_like(t_test)], axis=1))\n",
        "rf_ipsw_y1_out = rf_ipsw.predict(np.concatenate([x_test, np.ones_like(t_test)], axis=1))\n",
        "\n",
        "rf_ipsw_te_in = rf_ipsw_y1_in - rf_ipsw_y0_in\n",
        "rf_ipsw_te_out = rf_ipsw_y1_out - rf_ipsw_y0_out"
      ],
      "metadata": {
        "id": "LdDN8YJia1Go"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X-learner"
      ],
      "metadata": {
        "id": "G3Ywm9f4cVFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X-Learner\n",
        "xl = XLearner(models=RandomForestRegressor(), propensity_model=RandomForestClassifier())\n",
        "xl.fit(y_train, t_train.flatten(), X=x_train)\n",
        "\n",
        "xl_te_in = xl.effect(x_train)\n",
        "xl_te_out = xl.effect(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKevWu_qcWB0",
        "outputId": "47306c29-ea4a-48a5-d547-7798a4344f62"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Evaluate your models.\n",
        "\n",
        "    Measure ATE and PEHE errors."
      ],
      "metadata": {
        "id": "J9rDCXujcuhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ATE ERROR:\n",
        "true_ate = 1.05\n",
        "\n",
        "rf_ate_in = ate_error(rf_te_in, true_ate)\n",
        "rf_ate_out = ate_error(rf_te_out, true_ate)\n",
        "\n",
        "rf_ipsw_ate_in = ate_error(rf_ipsw_te_in, true_ate)\n",
        "rf_ipsw_ate_out = ate_error(rf_ipsw_te_out, true_ate)\n",
        "\n",
        "xl_ate_in = ate_error(xl_te_in, true_ate)\n",
        "xl_ate_out = ate_error(xl_te_out, true_ate)\n",
        "\n",
        "results = []\n",
        "results.append(['RF', rf_ate_in, rf_ate_out])\n",
        "results.append(['RF (IPW)', rf_ipsw_ate_in, rf_ipsw_ate_out])\n",
        "results.append(['XL', xl_ate_in, xl_ate_out])\n",
        "\n",
        "cols = ['Method', 'ATE train', 'ATE test']\n",
        "\n",
        "df = pd.DataFrame(results, columns=cols) #they are error so the lower the better\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "a4V4INxFcwVM",
        "outputId": "0b9bb172-a86f-4f35-f91d-7b92240916b2"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Method  ATE train  ATE test\n",
              "0        RF   2.884445  2.884445\n",
              "1  RF (IPW)   2.866540  2.967882\n",
              "2        XL   2.929523  2.945682"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-450028f1-7b98-4bf6-a97e-9da02bec174b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>ATE train</th>\n",
              "      <th>ATE test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RF</td>\n",
              "      <td>2.884445</td>\n",
              "      <td>2.884445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RF (IPW)</td>\n",
              "      <td>2.866540</td>\n",
              "      <td>2.967882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XL</td>\n",
              "      <td>2.929523</td>\n",
              "      <td>2.945682</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-450028f1-7b98-4bf6-a97e-9da02bec174b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-450028f1-7b98-4bf6-a97e-9da02bec174b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-450028f1-7b98-4bf6-a97e-9da02bec174b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confidence intervals"
      ],
      "metadata": {
        "id": "VTnW3xnPd5n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_ci(data, ci=0.95):\n",
        "  l_mean = np.mean(data)\n",
        "  lower, upper = st.t.interval(ci, len(data)-1, loc=l_mean, scale=st.sem(data))\n",
        "  return l_mean, lower, upper"
      ],
      "metadata": {
        "id": "b5EhN-L1d7Pj"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_ate_bounds = mean_ci(rf_te_out)\n",
        "rf_ipsw_ate_bounds = mean_ci(rf_ipsw_te_out)\n",
        "xl_ate_bounds = mean_ci(xl_te_out)\n",
        "\n",
        "results = []\n",
        "results.append(['RF', rf_ate_bounds[0], rf_ate_bounds[1], rf_ate_bounds[2]])\n",
        "results.append(['RF (IPW)', rf_ipsw_ate_bounds[0], rf_ipsw_ate_bounds[1], rf_ipsw_ate_bounds[2]])\n",
        "results.append(['XL', xl_ate_bounds[0], xl_ate_bounds[1], xl_ate_bounds[2]])\n",
        "\n",
        "cols = ['Method', 'ATE mean', 'CI lower', 'CI upper']\n",
        "\n",
        "df = pd.DataFrame(results, columns=cols)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bZ-opmkfd-Wk",
        "outputId": "a0eb425e-4b1d-4250-ebca-f5004c6a09c8"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Method  ATE mean              CI lower             CI upper\n",
              "0        RF  3.934445              3.843932             4.024957\n",
              "1  RF (IPW)  4.017882              3.726686             4.309079\n",
              "2        XL  3.995682  [3.8186824482721837]  [4.172680762083964]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddd056af-d4c9-44c0-b379-857d3edfd809\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>ATE mean</th>\n",
              "      <th>CI lower</th>\n",
              "      <th>CI upper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RF</td>\n",
              "      <td>3.934445</td>\n",
              "      <td>3.843932</td>\n",
              "      <td>4.024957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RF (IPW)</td>\n",
              "      <td>4.017882</td>\n",
              "      <td>3.726686</td>\n",
              "      <td>4.309079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XL</td>\n",
              "      <td>3.995682</td>\n",
              "      <td>[3.8186824482721837]</td>\n",
              "      <td>[4.172680762083964]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddd056af-d4c9-44c0-b379-857d3edfd809')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddd056af-d4c9-44c0-b379-857d3edfd809 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddd056af-d4c9-44c0-b379-857d3edfd809');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisations"
      ],
      "metadata": {
        "id": "P1PUajxheDcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.boxplot([rf_te_out, rf_ipsw_te_out, xl_te_out.flatten()], labels=['RF', 'RF (IPW)', 'X-learner'])\n",
        "plt.ylabel('Treatment Effect')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "tehZYlkdeFer",
        "outputId": "2cc736e5-9c80-41f5-9a65-f1ea439419e7"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rajouté par lui pour terminer\n",
        "ate_lr = ate_error(lr_cate, test['te'])\n",
        "ate_dr = ate_error(dr_cate, test['te'])\n",
        "\n",
        "pehe_lr = pehe_error(lr_cate, test['te'])\n",
        "pehe_dr = pehe_error(dr_cate, test['te'])"
      ],
      "metadata": {
        "id": "WGWmY-mMiv10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}