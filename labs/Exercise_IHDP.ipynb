{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise IHDP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubertadrien/IADS_ML_for_causal_inference/blob/main/labs/Exercise_IHDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBoPcfD9l9V8"
      },
      "source": [
        "# Causal Inference - Exercise (IHDP)\n",
        "\n",
        "This is an opportunity for everyone to put into practice everything we have learnt so far. The data for this exercise comes from Infant Health Development Program study and was modified specifically for causal inference estimation purposes. More precisely, this dataset was formally introduced by [Hill (2011)](https://doi.org/10.1198/jcgs.2010.08162). It is a commonly used semi-simulated dataset in the CI community that combines pre-treatment covariates (X) and treatment assignments (T) from a real study, and simulated outcomes (Y). Because all outcomes are generated (both $y_1$ and $y_0$), we can measure individual as well as average treatment effect errors. For training purposes, only one of the outcomes is available to the estimator. The other is hidden and used only for evaluation purposes.\n",
        "\n",
        "The experiment where the covariates come from measured various aspects of premature infants and their mothers, and how receiving specialised childcare affected the cognitive test score of the infants later on. The treatment groups are made imbalanced by removing a subset of the treated individuals. The variables are a mixture of contonuous and binary features. Treatment is binary. The outcome Y is continuous. Overall, we have 25 background features X. The data consists of 747 samples (139 treated, 608 control)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcflqEHyquI_"
      },
      "source": [
        "In terms of evaluation metrics, we are interested in predicting both individual and average treatment effects for this task. As the outcomes are simulated, we have access to both true outcomes $\\mathcal{Y}_1$ and $\\mathcal{Y}_0$ for each individual (i). As a result, we have access to true ITEs and true ATE:\n",
        "\n",
        "$$ITE^{(i)} = \\mathcal{Y}_1^{(i)} - \\mathcal{Y}_0^{(i)}$$\n",
        "\n",
        "$$ATE = \\mathbb{E}[ITE]$$\n",
        "\n",
        "We can define our predictions as:\n",
        "\n",
        "$$\\widehat{ITE}^{(i)} = \\hat{y}_1^{(i)} - \\hat{y}_0^{(i)}$$\n",
        "\n",
        "$$\\widehat{ATE} = \\frac{1}{n}\\sum \\limits_{i=1}^{n}\\widehat{ITE}^{(i)}$$\n",
        "\n",
        "This allows us to define measurement errors with respect to each as:\n",
        "\n",
        "$$\\epsilon_{PEHE} = \\sqrt{\\frac{1}{n}\\sum \\limits_{i=1}^{n}(\\widehat{ITE}^{(i)} - ITE^{(i)})^2}$$\n",
        "\n",
        "$$\\epsilon_{ATE} = \\left| \\widehat{ATE} - ATE \\right|$$\n",
        "\n",
        "Where PEHE stands for Precision in Estimation of Heterogeneous Effect, and which essentially is a Root Mean Squared Error (RMSE) between predicted and true ITEs. Implementations of both metrics are provided below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao4shEd7IRNb"
      },
      "source": [
        "def rmse(a, b):\n",
        "    return np.sqrt(((a - b)**2).mean())\n",
        "\n",
        "def ate_error(pred_te, true_te):\n",
        "  return np.abs(np.mean(pred_te) - np.mean(true_te))\n",
        "\n",
        "def pehe_error(pred_te, true_te):\n",
        "  return rmse(true_te, pred_te)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-3Z9QlR1tdA"
      },
      "source": [
        "We suggest the following steps:\n",
        "1. Import packages.\n",
        "    1. Remember to install EconML if you want to use it.\n",
        "2. Data.\n",
        "    1. Can be accessed at the following URLs:\n",
        "        1. Training: https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_train.npz\n",
        "        2. Testing: https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_test.npz\n",
        "    2. Use 'wget' command to download them into the notebook (or upload manually).\n",
        "    3. Explore the data (print a few samples, plot distributions - see plot_dist function below).\n",
        "3. Data pre-processing.\n",
        "    1. No data splitting required (train and test already provided).\n",
        "    2. Scaling.\n",
        "4. Train estimators of your choice (re-use already presented ones or explore different methods.\n",
        "  1. EconML - [CATE estimators](https://econml.azurewebsites.net/reference.html#cate-estimators).\n",
        "  2. scikit-learn - [supervised methods](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning).\n",
        "5. Make predictions.\n",
        "6. Evaluate your models.\n",
        "    1. Measure ATE and PEHE errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcy1W32ix3o8"
      },
      "source": [
        "def _trim_axs(axs, N):\n",
        "    axs = axs.flat\n",
        "    for ax in axs[N:]:\n",
        "        ax.remove()\n",
        "    return axs[:N]\n",
        "\n",
        "def plot_dist(data, bins=10):\n",
        "    \"\"\"\n",
        "    data: 2-dimensional numpy array\n",
        "    bins: number of bins in the histograms\n",
        "    \"\"\"\n",
        "    if data.shape[1] > 1:\n",
        "        sq = math.sqrt(data.shape[1])\n",
        "        d_ceil = math.ceil(sq)\n",
        "        d_floor = math.floor(sq)\n",
        "\n",
        "        if (d_ceil * d_floor) >= data.shape[1]:\n",
        "            n_rows = d_floor\n",
        "            n_cols = d_ceil\n",
        "        else:\n",
        "            n_rows = n_cols = d_ceil\n",
        "\n",
        "        _, axs = plt.subplots(n_rows, n_cols)\n",
        "        axs = _trim_axs(axs, data.shape[1])\n",
        "\n",
        "        for i, ax in enumerate(axs):\n",
        "            ax.hist(data[:, i], bins=bins)\n",
        "    else:\n",
        "        plt.hist(data, bins=bins)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start of the exercise:\n",
        "1. Import packages."
      ],
      "metadata": {
        "id": "O7EGUQX9A4LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install econml"
      ],
      "metadata": {
        "id": "OmWktr4sA3QE",
        "outputId": "23d1650d-9c74-4227-b4b8-2487ed3c859a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting econml\n",
            "  Downloading econml-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from econml) (1.1.0)\n",
            "Requirement already satisfied: statsmodels>=0.10 in /usr/local/lib/python3.7/dist-packages (from econml) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn<1.2,>0.22.0 in /usr/local/lib/python3.7/dist-packages (from econml) (1.0.2)\n",
            "Collecting shap<0.41.0,>=0.38.1\n",
            "  Downloading shap-0.40.0-cp37-cp37m-manylinux2010_x86_64.whl (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from econml) (2.2.3)\n",
            "Collecting sparse\n",
            "  Downloading sparse-0.13.0-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from econml) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from econml) (1.21.6)\n",
            "Collecting dowhy<0.8\n",
            "  Downloading dowhy-0.7.1-py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>1.4.0 in /usr/local/lib/python3.7/dist-packages (from econml) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from dowhy<0.8->econml) (2.6.3)\n",
            "Requirement already satisfied: sympy>=1.4 in /usr/local/lib/python3.7/dist-packages (from dowhy<0.8->econml) (1.7.1)\n",
            "Collecting pydot>=1.4\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->econml) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->econml) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot>=1.4->dowhy<0.8->econml) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->econml) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.2,>0.22.0->econml) (3.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap<0.41.0,>=0.38.1->econml) (0.51.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap<0.41.0,>=0.38.1->econml) (1.3.0)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap<0.41.0,>=0.38.1->econml) (21.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap<0.41.0,>=0.38.1->econml) (4.64.0)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.10->econml) (0.5.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.4->dowhy<0.8->econml) (1.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap<0.41.0,>=0.38.1->econml) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap<0.41.0,>=0.38.1->econml) (0.34.0)\n",
            "Installing collected packages: slicer, pydot, sparse, shap, dowhy, econml\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 1.3.0\n",
            "    Uninstalling pydot-1.3.0:\n",
            "      Successfully uninstalled pydot-1.3.0\n",
            "Successfully installed dowhy-0.7.1 econml-0.13.1 pydot-1.4.2 shap-0.40.0 slicer-0.0.7 sparse-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from econml.metalearners import XLearner\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nEpe2kqeBoDk",
        "outputId": "33c1a5ca-c192-41c0-c07e-ddec177d2633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data."
      ],
      "metadata": {
        "id": "i5snWR5tBcuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training data:\n",
        "!wget https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_train.npz\n",
        "data_train = np.load('ihdp_train.npz')\n",
        "\n",
        "#Testing data:\n",
        "!wget https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_test.npz\n",
        "data_test = np.load('ihdp_test.npz')"
      ],
      "metadata": {
        "id": "VFrcxITkBfRt",
        "outputId": "e1203efa-5009-4df9-9502-806850a4bbd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-28 13:40:29--  https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_train.npz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dmachlanski/iads-summer-school-causality-2022/main/labs/data/ihdp_train.npz [following]\n",
            "--2022-07-28 13:40:29--  https://raw.githubusercontent.com/dmachlanski/iads-summer-school-causality-2022/main/labs/data/ihdp_train.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 151488 (148K) [application/octet-stream]\n",
            "Saving to: ‘ihdp_train.npz.1’\n",
            "\n",
            "\rihdp_train.npz.1      0%[                    ]       0  --.-KB/s               \rihdp_train.npz.1    100%[===================>] 147.94K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-07-28 13:40:29 (62.0 MB/s) - ‘ihdp_train.npz.1’ saved [151488/151488]\n",
            "\n",
            "--2022-07-28 13:40:29--  https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/ihdp_test.npz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dmachlanski/iads-summer-school-causality-2022/main/labs/data/ihdp_test.npz [following]\n",
            "--2022-07-28 13:40:29--  https://raw.githubusercontent.com/dmachlanski/iads-summer-school-causality-2022/main/labs/data/ihdp_test.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17760 (17K) [application/octet-stream]\n",
            "Saving to: ‘ihdp_test.npz’\n",
            "\n",
            "ihdp_test.npz       100%[===================>]  17.34K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 13:40:29 (87.2 MB/s) - ‘ihdp_test.npz’ saved [17760/17760]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the data:\n",
        "print(data_train.files)\n",
        "print(data_test.files)"
      ],
      "metadata": {
        "id": "zIC-5SaYCo1l",
        "outputId": "ac39859c-8ae6-4595-de72-f08680fc87b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['x', 't', 'y', 'te']\n",
            "['x', 't', 'y', 'te']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape 'T' necessary --> would not work later"
      ],
      "metadata": {
        "id": "ZVHrvL0SC9JU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}